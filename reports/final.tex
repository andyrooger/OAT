\documentclass{report}
\usepackage{amssymb,amsmath}
\usepackage[mathletters]{ucs}
\usepackage[utf8x]{inputenc}
\usepackage[breaklinks=true,unicode=true,pdfborder={0 0 0},colorlinks=false]{hyperref}
\usepackage{listings}
\lstdefinelanguage{obftool}{morekeywords={help,quit,status,parse,explore,format}}
\lstset{language=Python, numbers=left, showstringspaces=false, frame=single}
\usepackage{pst-gantt}
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setcounter{secnumdepth}{0}

% For title page
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\begin{document}
\begin{titlepage}

\begin{center}

% Upper part of the page
\textsc{\LARGE Imperial College London}\\[1.5cm]
\textsc{\Large Undergraduate Individual Project}\\[0.5cm]

% Title
\HRule \\[0.4cm]
{\huge \bfseries Obfuscating Python 3000} \\[0.4cm]
\HRule \\[0.4cm]

Code on git at: ssh://user@shell4.doc.ic.ac.uk/homes/asg08/git/ugproject.git \\[1.5cm]

% Author and supervisor
\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large
\emph{Author:}\\
Andy Gurden
\end{flushleft}
\end{minipage}
\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
\emph{Supervisor:} \\
Herbert Wikliky
\end{flushright}
\end{minipage}

\vfill

% Bottom of the page
{\large \today}

\end{center}
\end{titlepage}

\begin{abstract}
TODO write abstract!
\end{abstract}

\section*{Acknowledgements}

TODO - write acknowledements - Hayley Hannam, Herbert Wikliky, Chris Hankin, Alex Lamaison

\tableofcontents

\clearpage

\section{Introduction}

With the increasing popularity of interpreted languages like Java or Python, we are starting
to see a change in the way that program code is distributed.

Not so long ago, a programmer could write their program in a compiled language such as C. This would then be compiled
to machine code for a given architecture, and the program could be handed out to anyone without
worrying about whether a hacker or reverse-engineer could recover the original source code.
Of course, it can be done and there are tools to reverse the translation, called decompilers \cite{cdecomp}, but it
is a difficult process and there are methods to make this harder \cite{disres}.

The difference for interpreted languages is that much more of the original code is kept in the
distributed format. Java code, for example, is usually distributed as bytecode for the Java Virtual
Machine (JVM). This still holds information about high level constructs such as class and method names for example \cite{classinfo},
making it much easier to decompile a Java class.

In a language like Python it is usually raw source code that is distributed, therefore a
user need not put in any effort to view the inner workings of the program. While this is good
for the security of a user \cite{noobf}, it is often the case that the author will not want sensitive,
perhaps proprietary, parts of their code open to inspection or theft. With this in mind, we will work on ways to protect it.

We should note that there are existing solutions for the protection of Python source code, examples of which vary in quality.
These will be discussed in the next section, along with their drawbacks and areas to which we can contribute further.

The approach we will take to the above problem is to obfuscate the Python source code. This technique involves changing the
original program in some way so that it is more confusing to a reader or more difficult to analyse, while still remaining correct.

More specifically, during this project we shall implement a basic functioning, but extensible, obfuscator
that can modify the control flow of a program with the aim of diverting a human reader from its actual
function. This will act upon Python source code and should help to address the issue described above.
In the interest of evaluation, we will also create a sister program that will try to reverse the modifications performed by the
obfuscator with the aim of recovering the original source code. 
We shall aim to create these tools by taking a subset of obfuscation techniques used on other languages (e.g.
loop flattening or instruction reordering \cite{taxobftrans}) and looking at how well these will transfer to such a dynamic language as Python.

On the surface this may appear rather simple, however as Python is such a highly dynamic language it can be very difficult to analyse
\cite[p13]{staticanal} as thoroughly as a more traditional compiled language such as Java. In such languages, it is much easier to perform a static
analysis of the code. This is simply not feasible for many applications in Python, yet many program transformations will require this type of
thorough analysis. Issues in this area may appear or they may not, depending on the techniques we decide to implement, and it will be a part of
this project to notice and evaluate these issues.

\section{Background}

Here we will discuss Python and some solutions for protecting code, as well as some obfuscation techniques
and current tools.

\subsection{Python}

As we have discussed in the introduction, the project aims to implement known obfuscation techniques on Python source.
The language is used widely, from the popular web framework Django \cite{django} through many applications
from Google \cite{pygoogle} and even embedded as a scripting language for extensions in programs like GNU
Image Manipulation Program (GIMP) \cite{gimp}. Due to its wide and varied use, it is of increased importance
that someone wishing to protect their Python code from theft or reverse-engineering can do so.

To be specific about the code and techniques, we will restrict our efforts to using obfuscation methods that will
result in standard Python code so that it is portable across any of the many Python runtime implementations. The version
of Python we will be working with is 3.x (nicknamed 3000 or py3k) for both source and generated code. The most popular
version of Python is still 2.x, however this version will soon ``become stale'' as the language moves towards 3.x, on its way
dropping some compatibility with 2.x.

\subsubsection{Methods of Protection}

There are a number of ways Python developers currently try to hide or protect their code, with varying degrees
of success and security.

One method is to use a Python tool called Freeze. This tool will simply take given source code and compile
it to bytecode. This will be combined with necessary parts of the runtime to allow a program to run
on systems without Python installed. As it says in the README \cite{freezereadme} this provides little if any
protection as Python's standard library comes with a disassembler ready to view the bytecode. There are also
tools such as AntiFreeze \cite{pirates} to help analyse the code, as well as a program called
decompyle \cite{decompyle} that will actually try to generate the original source for older bytecode ($\le$version
2.3). There is a similar tool to Freeze, called py2exe \cite{py2exe}, that will create a Windows executable but
this too suffers from the same problems.

From the above paragraph, it's easy to spot that just distributing the Python bytecode, another method occasionally
used, also fails to thwart reverse-engineering attempts. In fact there is another problem
with these methods and any others that rely on Python bytecode. Bytecode is an implementation detail \cite{dis}
of the default Python implementation, CPython. Relying on this to distribute code would glue any
user to a specific implementation of Python and possibly even to a specific version. This would remove the portability
expected from a Python program and contradict the condition that solutions must be portable, specified earlier.

A more secure solution for protecting Python code, and one that works for many people, is to remove the most
sensitive parts and replace them with C extensions to the Python program. This way the code becomes machine
code, it can use the wealth of obfuscation tools for C and being compiled machine code makes it much
harder to reverse engineer. Again though, this is based on CPython's ability to include C modules, restricting a
user to a particular runtime as well as a particular machine architecture (that the modules are compiled for).

A portable way to protect the code would be to obfuscate it, performing source to source translations that can
confuse a reader or program analyser. This is not and will never be a perfect solution, because all attempts
to avoid reverse engineering will be overcome eventually. The difference between one method of protection and
another is the time and effort taken to break it and how much the result is worth to the attacker. There are already
programs for obfuscating Python code, though the selection is limited. These will be discussed later.

\subsubsection{Ethics of Obfuscating}

Although it may not be obvious, there are ethical and possibly even legal implications to obfuscation.
Specifically for Python, the language is based on a philosophy of clear and readable code, and actually
enforces this by the design of the grammar. Obviously, obfuscation is an attempt to take this away.

This hits out against certain expectations a user may have about a Python program. A key benefit of having your
software handed to you in source form is that you always know what it's doing. Deliberately obscuring the
function of software, but in a format that is almost always open for inspection, removes trust. The vendor or developer is
denying the user trust by not allowing them to use the software as they wish, but more importantly the user's
trust in the software can be lost.

If the software is hiding what it is doing this could be for a legitimate reason, such as hiding novel ideas
from competitors, or it could be to mask malicious content. A user or program, provided the obfuscation is
good enough, cannot tell which the reason is. This is a technique often employed by malware
writers to avoid detection by anti-virus software \cite{dycodeobf}. In fact, it has been argued that any and
all obfuscated code should be treated as if it were malware \cite{noobf}, assuming software is guilty until
proven otherwise.

My view and the view we will take for the remainder of the paper is that these issues create more reason for
building a tool such as this. By allowing issues such as those described above to block research into a subject
we are making ourselves much more vulnerable to those who would abuse the technology. Those who may abuse any
product of this project will be free to do so, as will those who would use the tools and information legitimately.

It is important to note that although my conclusion on this subject would be the same were I based outside of
the UK, the legal implications stemming from it may not be. For example in German law, clause 202(c) \cite{202c}
could make it illegal to write or distribute this software if it could be used for
certain forms of cybercrime. As discussed above, it probably could, and would have implications for anyone distributing
or using the information presented here.

\subsection{Types of Obfuscation}

Having decided to obfuscate the code from source to source, it is worth taking a look at the types of
obfuscation already used, how they are useful and which we will pursue. We will classify them into 3 categories
suggested by \cite[p10]{desevobf}.

\subsubsection{Layout Obfuscation}

These will apply transformations to the source language or possibly bytecode that do not affect the running of the
program. This is a very common form of obfuscation \cite[p10]{desevobf}, and involves transformations such as removing comments,
scrambling identifiers, or removing as much whitespace as possible to make the code unreadable.

Comments and identifiers often hold a lot of semantic information as they are designed to do.
Removal of this information by deletion or renaming is quite effective and almost always irreversible. Other transformations involving syntax
can be easily removed by a source formatter and so will only be effective against an impatient human.

While some of these transformations may be easy to perform in traditional languages, there are places in which
Python's constructs can cause problems. Fortunately these kinds of transformations are already covered in existing
tools, although these are not necessarily compatible with Python 3. For these reasons, we will be focusing on other forms of
obfuscation which have received less attention.

\subsubsection{Data Obfuscation}

This type of obfuscation transforms data layout and can help to obfuscate the structure of the program. It can be
particularly helpful in Python as the language makes it very easy to inspect programs as they run, dissecting data
structures and learning about how the program works.

Examples of techniques here include adding extra layers of inheritance into a class's inheritance tree or traversing arrays
in unexpected orders.

While this type of obfuscation can be useful, our focus will be primarily on the next type of obfuscation.

\subsubsection{Control-flow Obfuscation}

Control flow obfuscation alters or obscures the control flow of the original code. This will confuse an analyser as to the
true control flow of the program. For example, a transformation may introduce a conditional branch to dead or broken code
that never happens, however the value of this condition is hard for the analyser to prove or evaluate before runtime.

Reversal of this type of transformation can require careful analysis and can be difficult to perform. Often the reversal
of this type of transformation could result in optimisation of the code.

These are the type of transformations we will attempt to implement first.

\subsection{Tools}

We have previously seen that there are tools to do similar obfuscation in Python already. We will now discuss some
examples of these, as well as other tools to try to reverse the transformations.

\subsubsection{Python Obfuscation}

There are a number of tools out there that claim to do this. For example BitBoost Systems have a Python obfuscator \cite{bitboost}
that claims to use layout obfuscation as well as ``psychologically inspired techniques'' to confuse readers. Sadly, as a
single machine license costs \$200 it is not possible to test the tool outside of their web-based demo.

In the free realm, the freeze \cite{freezereadme} or py2exe \cite{py2exe} programs will also obfuscate python very slightly,
though only by distributing bytecode rather than raw source.

Alternatively pyobfuscate \cite{pyobf} will scramble a subset of the identifiers used in programs as well as performing
some other layout transformations. It has its limitations however \cite{pyobf}, so is not powerful enough for real use cases.

pyobfuscate has not been updated since 2005, and is unable to run on any Python version since 2.6. Many of the other tools are in
a similar situation and so it is unlikely these will be able to cope with recent versions of Python code.

\subsubsection{Analytic Tools}

For analysis of Python code there are more tools available.

Firstly to reverse the very basic syntax transformations there are a great number of Python pretty printers such as
pygments \cite{pygments} or PythonTidy \cite{pythontidy}. This should never be a particularly difficult task as Python is
designed with readability in mind and enforces clear formatting in its syntax.

PyLint \cite{pylint}, PyChecker \cite{pychecker} and PyFlakes \cite{pyflakes} are all tools designed to help look for possible
bugs in Python code and so may have some use in checking validity of obfuscated source files. They also look for bad design and so
could help to determine how difficult a program is to understand for a human reader.

PyDev \cite{pydev} is a plugin for the Eclipse IDE for developing in Python. It performs some useful code analysis on projects to detect
possible bugs and allow easy refactoring of code. While it is implemented in Java as well as Jython (an alternate Python runtime)
it should be possible to reuse the ideas if needed. Tools for refactoring are easily available as PyDev uses Bicycle Repair
Man \cite{bikerepair}, a Python library designed specifically for this task. PyDev also definitely supports Python 3.x as opposed to the
other tools in which this is unclear.

To attempt decompilation of the Python bytecode if necessary, there is a tool called decompyle \cite{decompyle} that has already been
mentioned. This should not be necessary though as we have already discussed reasons not to use bytecode during the project.

Some of the greatest  tools for analysis come from Python itself. Programs are often run from an interactive Python interpreter, and this
can be used for easy dissection. Python's standard library comes with modules for parsing, assembling and disassembling source code.
There are also tools for creating interactive sessions within the program. For example by inserting the following code at any point
in the program:

\begin{lstlisting}
from code import InteractiveConsole
InteractiveConsole(locals()).interact()
\end{lstlisting}

We can effectively create a breakpoint and launch an interactive shell to inspect and possibly modify the current local
variables. The program will continue as soon as the shell is closed.

Other more sophisticated tools are available for debugging or inspection such as AntiFreeze \cite{pirates} if necessary,
however Python provides more than enough in its standard library.

\section{Creating the Software}

The end product of this project is intended to be a usable source to source Python obfuscator as well as an analytic tool
to assess its effectiveness. If we are to make sure the transformations we make to programs are really correct, we should
know the ins and outs of the language well. This way we can easily pick up on language features that may contradict our
expectations about the behaviour of the code. For example it's easy to naively assume that a simple assignment to an object
variable would be free of side effects. This is not the case, depending on the actual code an assignment can run absolutely
anything \cite{pyprop} and doesn't even have to assign the given value to a variable.

To learn the language to the desired degree we will also use it to write our software. The hope being that heavy use will help to
drill out some of the less obvious features. For the same reason, we will be writing the code specifically to run on a Python version 3.x
interpreter.

Having chosen the language and version we will use to develop in, we need to design the software we are about to write. This is split into a few basic building
blocks. Specifically the following:

\begin{itemize}
\item A Python parser/lexer to read and make sense of Python source files.
\item Implementations of a number of obfuscating transformations.
\item Implementations of a number of analytic techniques.
\item A Python writer to take our abstract representation of the source code and output a file.
\item A user interface.
\end{itemize}

The most fundamental parts here in the workflow are the parser/lexer and the writers for the source files.
Without these the other parts are useless, so this is where the implementation will begin.

\subsection{Reading and Writing Python Source Code}

It is easy to assume that reading and writing Python source code are two discrete problems. In fact this is not the case,
when looking at most possible solutions we shall see that the method or tools used to read the source code are usually deeply
entwined with each other. This will either be because they are part of the same toolset, or just because they work so closely together;
any data structures output by one need to be readable by the other. For this reason we shall tackle these problems as one.

There are plenty of free tools that read and write source as part of their tasks. For example PyDev, mentioned in the background section, will
perform these tasks during code formatting. For this project we have the choice between writing software from scratch, attempting
to recycle relevant parts from free projects, or using libraries to take the work away from ourselves.

The first option we should look at is to write the code from scratch. This could be very time consuming, requiring
us to write complicated software as well as studying documentation on Python's grammar which is freely available online \cite{pygrammar}.
While the language is well documented it does seem wasteful to repeat work that has been done in so many other places.

Next we look at extracting the functionality from other free (open source) software. The most fitting source to source translation tools
we could use for this are PyDev or the 2to3 tool \cite{2to3}, used to convert Python 2.x source code to Python 3.x. Ultimately we will not
delve into these tools due to the amount of time we could squander searching for relevant parts of code. It is likely we
would come to the conclusion that they outsource most of the work to separate libraries anyway.

This leaves us using libraries. In fact the 2to3 documentation points to a Python standard library called \texttt{lib2to3} that can be used to
perform automatic translation on Python source. Unfortunately further reading shows that the library API is unstable and could change by
the next release. This is not a situation we wish to to deal with and so is not really a viable option.

Fortunately the Python standard library contains a number of modules devoted to its own language. By using these to parse a source file
we can hold the source as an abstract syntax tree or AST. This will give us the freedom to transform the language as we like and the only code we
will need to write would be for the AST translations and an AST to source code writer.

There are some flaws to storing the program as an AST, as this structure drops certain information.
For example the \texttt{elif} statement, meaning the same as an \texttt{else}-\texttt{if} statement in other languages allows many tests without
additional levels of nesting in source. When this construct is parsed it becomes an \texttt{if} statement within an \texttt{else} statement and
can create large changes to the expected code and level of nesting. The example below shows the result of translating the code on the left hand
side to an AST and back, writing the result on the right.

\begin{minipage}[b]{0.4\linewidth}
\centering
\begin{lstlisting}[basicstyle=\small]
if item == "alice":
    gender = "female"
elif item == "bob":
    gender = "male"
elif isname(item):
    gender = "unknown"
else:
    raise ValueError
\end{lstlisting}
\end{minipage}
\hspace{1cm}
\begin{minipage}[b]{0.5\linewidth}
\centering
\begin{lstlisting}[basicstyle=\small]
if item == "alice":
    gender = "female"
else:
    if item == "bob":
        gender = "male"
    else:
        if isname(item):
            gender = "unknown"
         else:
             raise ValueError
\end{lstlisting}
\end{minipage}

Information such as comments are also dropped from the representation. These seem to be reasonable compromises however and so
using Python's \texttt{ast} module and writing our own AST to source writer is the option we will use. It gives a lot of freedom, whilst
being fast to write.

Before we start to design our source writers, we should think about the data structures we will be using to store information. As we don't have
control of the \texttt{ast} module, we cannot decide what format will be output when parsing a file. In fact, the value we should receieve from
a successfully parsed file will be derived from the \texttt{ast.AST} class. More specifically it will be a child of \texttt{ast.mod}, either
\texttt{ast.Module}, \texttt{ast.Interactive}, \texttt{ast.Expression} or \texttt{ast.Suite} depending on the context in which we are parsing.

It may be tempting to use this format throughout our software, however it does have its drawbacks. We will take a look at the design first to see why.

An object of any class derived from \texttt{ast.AST} represents a node in the AST grammar given in the documentation for the \texttt{ast} module. The
type of the node is the name of the class it belongs to. Each of these nodes can have a number of attributes or children, these are either of basic
types such as strings and integers or they are single or lists of other \texttt{ast.AST} nodes.

For most types of node the names of these children vary so it is useful to be able to find out their names from the object we are inspecting. For this we
look at the \texttt{\_fields} attribute, which is a tuple of all fields names. Using this we can look through the whole tree without worrying about the type
of individual nodes. There is also an \texttt{\_attributes} attribute giving the names of attributes. These are \texttt{lineno} and \texttt{col\_offset} where
available. We access field or attributes as normal attributes of the class.

This is a nice system and will help with tasks such as exploring or displaying the tree, however it creates problems as it is not stored as a tree of the same
type. Instead it is stored as a tree of \texttt{ast.AST} nodes, lists, and basic types. Unfortunately this means any tree traversal will have to be designed to
cope with either having or not having a proper \texttt{ast.AST} node and cannot rely on being able to find or read a \texttt{\_fields} attribute. Additionally we
cannot add new attributes onto lists, and we see later that we need to do this for any node.

\subsubsection{Implementing Internal Data Structures}

As there are a lot of positives for using \texttt{ast.AST} nodes as our data structure, and as we are forced at least to begin with one of these nodes after parsing,
it does not make sense to start again from scratch. Instead our solution will be to create a wrapper class. This will hold our actual node, but provide a new set of
children - the wrapped version of each of our original children.

The wrapper class will be called \texttt{CustomAST} and provide a number of helpful methods:

\begin{description}
\item[\texttt{\_\_init\_\_(node)}] \hfill \\
Stores the given original \texttt{ast.AST} (or basic or list) type node in the attribute \texttt{\_node} and creates a dictionary mapping field names
to \texttt{CustomAST} children in the attribute \texttt{children}.

The dictionary is created by first taking string names for each of the node's children if they exist. For an \texttt{ast.AST} node this is easy.
Otherwise the node is a basic type and has no children, or the node is a list and we use string versions of indices into the list. Now we can
easily map these names to the children they refer to, and place the \texttt{CustomAST} versions of them into the dictionary.

We can also give a hybrid node to this constructor. This would be either a list containing normal nodes and \texttt{CustomAST} nodes, or an
\texttt{ast.AST} node with some \texttt{CustomAST} nodes as children. Children that are already \texttt{CustomAST} nodes will not be rewraped
and the given node will be altered to contain only normal nodes. This allows us to easily transform or create new nodes from \texttt{CustomAST}
nodes without dissecting them first.

\item[\texttt{type(asclass)}] \hfill \\
Gives either the class of the node used to create this \texttt{CustomAST} node, or the string name of that class. This is helpful to easily distinguish
the node type.

\item[\texttt{node()}] \hfill \\
Returns the original node used during creation. This is in case we need to use a function designed for \texttt{ast.AST} nodes.

\item[\texttt{is\_ast()}, \texttt{is\_basic()} and \texttt{is\_list()}] \hfill \\
Allows checking of the broad category that the node falls into. These say, respectively, whether the nodes is derived from \texttt{ast.AST}, whether
it is a basic type such as a string or integer, or whether it is a list.

\item[\texttt{is\_empty()}] \hfill \\
Checks whether this node actually represents the lack of a node. If a parent node has an optional field, rather than just deleting field when the child does
not exist, the child will be set to \texttt{None}. This will then become an empty node. Likewise, if a parent has a field that can hold multiple children, an
empty list would represent that none exist and so this is also an empty node.

\item[\texttt{temp\_list(*vargs)}] \hfill \\
When translating or transforming nodes, it is often useful to concatenate lists to each other. New lists of single \texttt{CustomAST} nodes can easily be
created using hybrid nodes as so: \texttt{CustomAST([node1, node2, ...])}.

Actually concatenating list nodes is harder, so this function will create a new \texttt{CustomAST} list node starting with this node. Each argument will either be
concatenated or appended to the new node, depending on whether the argument is a list or a single node.

\item[\texttt{become(node)}] \hfill \\
When transforming an AST we may want to edit the \texttt{CustomAST} node in place. This will make sure any and all parents still reference the correct
object. This function will replace the node it wraps by that of the given node to do just that.

\item[\texttt{ordered\_children()}] \hfill \\
Often we will want to iterate over all children in a specific order. This is especially important for a list node where we want to iterate from 0 to 1.
Unfortunately, after filling our \texttt{children} dictionary with fields and nodes, we cannot simply iterate over the keys. The iteration order will
depend on the hashing function used internally by the dictionary.

Instead we use this function to generate a list of fields in the correct order. This is also used later to generate iterators for the node.

\item[\texttt{location()}, \texttt{desc()} and \texttt{\_\_str\_\_()}] \hfill \\
These provide a tuple with line number and column number, a text description of the node and a combination of both respectively.

By providing \texttt{\_\_str\_\_}, we allow conversion from node to string using \texttt{str(node)}. This means we can program in a much more
descriptive manner.

\item[\texttt{\_\_getitem\_\_(item)}, \texttt{\_\_iter\_\_()}, \texttt{\_\_contains(item)\_\_} and \texttt{\_\_len\_\_()}] \hfill \\
These functions all work towards a more natural interaction with node objects. We can access children like a dictionary using \texttt{node["field"]}, or
iterate using \texttt{for field in node}.

We also have a membership test using \texttt{field in item} and number of children using \texttt{len(node)}. These can be used together by Python to provide
a lot of other useful functionality.

\end{description}

Now we can parse Python source code and we have produced the data structures as well as the conversion methods needed to represent the output. The next
step is to provide a writer for our structure to enable us to write back to source code.

\subsubsection{Implementing an AST to Source Code Writer}

We shall now describe a solid design and extendable implementation for this. The design is fairly simple.

We begin with an abstract class called \texttt{SourceWriter}. Any code wishing to write an AST to source code can expect to be given a writer
class that looks similar to this, and any writer classes should be derived from this base. \texttt{SourceWriter} will define a number of functions
to be used by its derived writer classes. Among the more important are:

\begin{description}
\item[\texttt{\_\_init\_\_(topast, out)}] \hfill \\
The constructor. This takes the top node of an AST tree to translate to source and a file-like object we can write our output into.

\item[\texttt{write()}] \hfill \\
Translates and writes the whole of our given AST into our output file.

\item[\texttt{\_write(node)}] \hfill \\
Writes out the given node (and any necessary children). This actually checks the type of the node and dispatches the work to the appropriate function.
If an appropriate function is not found then this function will raise an exception as in means we either have an invalid node or an invalid writer class.
The writing of any node should be done through here rather than the method for a specific node type.

\item[\texttt{\_ground\_write(s)}] \hfill \\
Writes the given string, \texttt{s}, to our file. Any function that wishes to write to file should be doing it through this function.
This allows added functionality such as being able to monitor the position in the file we are currently writing to.

\item[\texttt{\_inc\_indent(by)} and \texttt{\_dec\_indent()}]
These increase the indentation level by adding the specified string to the current whitespace, or decrease it by removing the most recent addition.
By giving a string rather than an indentation level we can choose between tabs or a certain number of spaces. We can even indent by strings such
as \texttt{">>>"} to indicate an interactive session.

\item[\texttt{\_write\_block(statements, indent)}]
Writes an entire block, consisting of the given statements. \texttt{indent} is a boolean value, so we can have a uniform method to choose how to
indent the block inside the function. This can be overridden by derived classes.

\item[\texttt{\_write\_\{classname\}(node)}]
These are all abstract methods that write specific node types for \texttt{\_write}. \texttt{classname} can be either the name of a basic type we
may want to write, or the name of an AST node class.

\end{description}

This design allows any node to be written recursively using the \texttt{\_write} method. When called, it will dispatch the work to an appropriate method who
in turn will either dispatch each of its components back to \texttt{\_write} or, for leaf nodes or small details, write itself using
\texttt{\_ground\_write}.

By using uniform functions for writing structures such as blocks, we allow a derived class to alter behaviour easily from
a single point. The benefit of doing so is that we make the source writer easily extendable to create pretty printers,
minifiers\footnote{Minification of a program involves shrinking its file size by removing as many unnecessary characters as possible. It is
often used for interpreted languages such as JavaScript that need to be lightweight for transmission.} or even, at a later date if we choose
to extend our implementation, a basic layout obfuscator.

Now as \texttt{SourceWriter} is an abstract class, we need to provide an implementation for each of its abstract methods. Our first concrete class
will be called \texttt{BasicWriter}. This should produce correct code but we will invest no effort in readability. By using \texttt{BasicWriter} as
a starting point, other classes can focus on layout or clever modifications without the need to worry about trivial parts of the implementation.

We will not discuss the implementation of \texttt{BasicWriter} as it is fairly simple. Each node is written with the bare minimum effort required
and there is no exciting processing that takes place. The only item of interest here would be to note that not all nodes are actually implemented;
there is a small group of nodes that represent context rather than content, such as whether a name is being loaded or assigned to. As these should
never be written, they instead raise a \texttt{NotImplementedError}.

As we will see shortly, the \texttt{BasicWriter} does not produce very palatable code. Therefore it is in our and our users interests to
create a writer with a greater focus on readability. This writer will be named \texttt{PrettyWriter} and can be used to ease the inspection of
translated code. As suggested previously it will be derived from \texttt{BasicWriter}, avoiding most of the work of creating a new writer.

The specific extensions we will include in \texttt{PrettyWriter} alter the output for only a handful of nodes:

\begin{description}
\item[\texttt{Expr} and \texttt{Str}] \hfill \\
An \texttt{Expr} node is a type of Python statement, this means it stands on its own line. If the \texttt{Expr} node contains only a \texttt{Str} node
(representing a string), it is known as a docstring. These are used for programatically accessible documentation and are usually represented
differently to normal strings.

By making the distinction between a string and a docstring we can ensure we recreate this difference in the written code. As the docstring conventions 
\cite{docstr} recommend, we use triple quotes and so multiline strings can actually be written on multiple lines. We also change some of the strings to
cope with differing indentation.

\item[\texttt{FunctionDef}] \hfill \\
Often in a function definition we need to specify large number of parameters. Each of these parameters can all be given default values, and Python 3.x
even gives us function annotations so we can add a comment after the name and default value of each parameter. \texttt{BasicWriter} will write all
of this on one line, which very quickly becomes unreadable.

We aim to fix this by guessing when the argument list will be long, and if so, writing each of the arguments on a separate line. The way we actually look
for long argument lists is by checking each of the arguments for annotations. If any exist, we assume it to be a long list.

\item[\texttt{list}] \hfill \\
Lists usually represent a suite or a list of statements. If this is the case, \texttt{BasicWriter} will write the statements one after another, each on a
new line. This can be hard to read and is very different from a human reader who will usually separate logical blocks of code with blank lines.

\texttt{PrettyWriter} will try to infer these logical blocks from the type of the statements and insert the necessary blank lines to split them. For instance,
\texttt{import} statements are grouped together and class or function definitions are always in a group by themselves.
\end{description}

Using this this class as our writer in future should allow us to concentrate on the effects of specific obfuscations later. It will avoid clouding the evaluation
of the success of a technique with the minor obfuscations introduced by \texttt{BasicWriter}.

To illustrate the differences between the two solid implementations of \texttt{SourceWriter}, following is a sample program passed through our implementation of
\texttt{BasicWriter} and \texttt{PrettyWriter}. We can see a large difference between the source code returned by the two writers, it is obvious that
\texttt{PrettyWriter} produces cleaner and more readable code.

Sample Program

\lstinputlisting[basicstyle=\tiny]{../../example/example.py}

Output from \texttt{BasicWriter}

\lstinputlisting[basicstyle=\tiny]{../../example/example.py.basicformat}

Output from \texttt{PrettyWriter}

\lstinputlisting[basicstyle=\tiny]{../../example/example.py.prettyformat}

All of these writers will be held in the \texttt{writer} package.

\subsection{Interacting with the Software}

The next important part to think about is the how the user will interact with the software. Without some form of front end, the
user would need to write their own program each time they want to use our obfuscation code. Let us first discuss the type of
interaction we, or a user, would will need to have with the software.

\subsubsection{Interaction Method}

Current tools such as pyobfuscate or BitBoost's obfuscator are automated. In pyobfuscate, which is one of the more interactive
of the tools, user interaction and control is limited to not much more than the choice of file to obfuscate, and indentation style. This means
that while a user does have a little control over what happens, they really just insert a file and are returned an
unreadable one.

We want to be able to effectively evaluate what our tool is doing to the source code. For this we need to be able to intimately control
which parts of the program are affected, and by which obfuscations. This would be unfeasable to attempt with an automatic program,
even one with tweakable parameters, therefore it is not really an approach we can use.

Knowing we have to be able to direct and control transformations, there are a few different ideas of how. In general, these fit into
either solutions that involve us interactively looking through the AST and choosing how to transform or analyse certain
nodes, or those that let us insert tags into the source code that mark structures and techniques for obfuscation.

There are methods already used in other tools that we could employ to tag code. For example the doctest module in the standard
library uses docstrings (programmatically accessible comment strings) to specify unit tests for the code. Instead of unit tests,
we could place some form of markup into the comments. This would allow us to specify transformations in text form, but we should
remember to remove the docstrings at the end of the obfuscation.

For example we could try the following format to indicate a function should have all of its statements reordered:

\begin{lstlisting}
def func(param1, param2, param2):
    """Reorder Statements: all
       I am a normal docstring.
    """

    statement_1
    statement_2
    ...
    statement_n
\end{lstlisting}

Another possibility would be to use empty decorators to mark functions or classes for transformation. These are usually used to
transform the code in some way at run time, but could easily do nothing and be picked up as flags for the obfuscator. Using this
method we would need to specify the decorators elsewhere and could write the above examples as:

\begin{lstlisting}
import obfuscate

@obfuscate.reorder("all")
def func(param1, param2, param3):
    """I am a normal docstring."""

    statement_1
    statement_2
    ...
    statement_n
\end{lstlisting}

This would require a separate file, called obfuscate here, that defines the decorators. Also we would need to remember to
remove these decorators after obfuscation, just like in the docstring example.

The trouble with these methods is that transformations would be restricted to single nodes that support either docstrings or
decorators. By placing this constraint on any obfuscations we want to make, we would be rejecting a huge range of options.

We can also try to create our own system to tag source code or nodes in an AST. If we choose to tag source code, we need
to either make sure our solution is valid Python syntax and so will translate cleanly into an AST using the \texttt{ast}
module, or that we can strip any tags out before parsing and still be able to match them up afterwards.

It then makes much more sense, if we are tagging code, to tag the AST directly. This way we are free to modify \texttt{CustomAST}
nodes in whatever way we like. Parsing will still work as normal as we do not have the AST yet, and we can feel safe that our AST
to source writers will still work as we create them ourselves.

Actually if we were to enable a user to browse and tag an AST, we would already have already created an interactive explorer for
the tree. It seems unreasonable to expect a user to use software such as this to tag their tree and then have to feed this tagged
tree into a separate application to perform the obfuscation.

This leads us back to an earlier suggestion of of obfuscating directly from the explorer. This way
a user can merely browse to a node of interest and tell the software immediately to perform the transformations they want. Any
parameters needed can be set at this point, and the user will be able to see the effect of their command as soon as they have issued
it.

There is also the possibility that some obfuscations may involve multiple nodes or require more complicated parameters. To cope with
this we can provide the interface, but allow a different method of interaction to be defined for each type of obfuscation.

At this point we have decided on the method we will use to interact with our software. The interface is expected to allow a user to
explore an AST generated from the program source. For any obfuscation type implemented, we will define and implement a bespoke method
of interaction from the AST explorer.

As well as browsing and obfuscating the AST, we also need to be able to generate the AST and convert it back to source code afterwards.
For this reason we will also need to include some way of parsing and writing the file.

\subsubsection{Designing the User Interface}

These decisions bring a new question, one of how the explorer will look. The two main choices are a command line tool or a GUI. Again
Python contains tools to make both much easier. These come in the form of libraries such as the cmd library \cite{pycmd} for command
interpreters or Tkinter \cite{pytkinter} for GUIs.

In the interest of speed of development, and as user friendliness is not the main focus for us, we will use a command interface.
More specifically we will implement an interactive interpreter designed to be similar to to a generic Unix shell.

Both the obfuscation and analytic parts of the software will be accessible from this interface, and so it will be named
oat (Obfuscation and Analysis Tool). As well making it easier for us to refer to the inteface, we have also opened the possibility
of creating a graphical interface to the toolset named goat.

In our implementation, the standard Python command interface offering has been extended to make it easy to plug new commands in as
objects, allowing easy extensions with new analytic techniques or new obfuscating transformations. Obviously the
interface is worthless without actually plugging in some commands. Before we start to look at the obfuscation and analysis of code, the set of commands
available from the interface is as follows:

\paragraph{Help}

This will list help for the program as a whole as well as individual commands. It is an essential tool for a user to find their way around a
command based program such as this one.

\paragraph{Quit}

Used to leave the program. Also very necessary as this is not built in to the default interpreter.

\paragraph{Status}

This will send a message to all other commands asking them to relay their status if they have anything to contribute. It can be
used to check the state of certain parts of the program.

\paragraph{Parse}

Actual parsing of Python source files is done using this command. It uses the Python library functions to do the parsing but also
deals with problems like finding the files and handling incorrect syntax. Once a correct source file is parsed, the resulting AST
is stored in memory for use by the other commands. It is also possible to save and load a previously edited AST, so long as the original
source file is retained.


\paragraph{Explore}

This is used to explore an AST generated by the parse command. It will always point to a particular node in the tree and allows
inspection of any of the nodes properties. It is also possible to traverse the tree, moving between any of the current node's parents or
children freely.

\paragraph{Format}

The integration point for the source writers. This can print either the whole abstract syntax tree or the subtree pointed to by
explore. The printing style can also be changed between basic or pretty, and possibly other styles if the writers for these are created in future.
If the user chooses, output from this command may be written to disk.

\paragraph{Mark and Reorder}

Will be introduced later.

Where possible all of these commands implement auto-completion to guide the user and save time.

The following is an example session:

\begin{lstlisting}[language=obftool,basicstyle=\small]
andyrooger@DellBoy:~/git/ugproject/src$ ./quickstart.py 
Welcome to this little obfuscation tool.
If you're confused, type help!
--) help

Documented commands (type help <topic>):
========================================
help  quit  status  parse  explore  format


--) help parse
usage: parse file

Parse a source file to an AST.

positional arguments:
  file  File to parse.

--) parse 
interactive    quickstart.py  thirdparty     writer         
--) parse quickstart.py

--) status
Parsed tree: <_ast.Module object at 0x1bdab90> : quickstart.py
Viewing node: Module

--) explore
Looking at: Module

Fields:
  body - Block of statements

--) explore body
Looking at: Block of statements

--) explore
Looking at: Block of statements

Fields:
  0 - Expr (line 7, col -1)
  1 - ImportFrom (line 9, col 0)
  2 - FunctionDef (line 11, col 0)
  3 - If (line 19, col 0)

--) explore 3
Looking at: If (line 19, col 0)

--) explore
Looking at: If (line 19, col 0)

Fields:
  test - Compare (line 19, col 3)
  body - Block of statements
  orelse - Block of statements

--) explore -a
Looking at: If (line 19, col 0)

Attributes:
  lineno - 19
  col_offset - 0

Fields:
  test - Compare (line 19, col 3)
  body - Block of statements
  orelse - Block of statements

--) format -f
if __name__ == '__main__':
    go()

--) quit
\end{lstlisting}

\section{Reordering Instructions}

In the previous section we saw the basic blocks of oat fall into place. The code
is already set to read, inspect, and write out Python source. Now we can move
on to fulfilment of the project aims; to analyse and obfuscate the code.

The first technique we will seek to implement is the reordering of instructions. As it is required that
any implemented obfuscating transformations have an accompanying analysis that can be used to (attempt to)
reverse the modification, we will also try to implement this.

\subsection{Aims}

Usually a (well-written) program is ordered in such a way as to make it easy for the reader to follow.

There are two aspects of the layout we could inspect here; the order of statements, and their grouping (i.e. blocks of statements
separated, for example, by blank lines). More often than not, the grouping (in a well written program) indicates
to the reader that all statements in a single group are aimed towards achieving a common goal.
Knowing this, it is easier for a human reader to read the program with a higher level understanding
of its function.

Likewise, the ordering of statements in a program often guides a reader through a human thought process. There may
be many other valid and equally correct orders for the statements, however the program will tend to be written in
an order most easy for the programmer to follow. This in turn tends to make it easier for the reverse engineer to follow.

We need not worry about breaking up the groups, these are lost during conversion from source to abstract syntax tree.
Therefore we will only be dealing in this section with reordering the statements in our programs.

\subsection{Effect}

As stated above, the tendency to insert this extra information in the order of statements is human in nature. To a machine the
order of instructions, if they are still correct, will not usually make a difference to a programatic analysis. We still have an
equivalent program as we have not removed or added any extra steps into the code, only changed the order.

This means it is mainly human analysis and understanding we will be hindering by removing this information. However good
our obfuscation is, depending on the particular code being obfuscated, a competent reverse engineer may well find it possible
understand still, or even be able to reorder the statements in such a way that they are closer the original program and clearer
to the human thought process. The positive token we take from the programatic analyser's blindness to these matters is that it
can be quite difficult to perform the reverse obfusction automatically.

\subsection{Method}

We have so far been talking about grouping and reordering of statements. To be clear, a statement here means any node in Python's abstract
grammar \cite{pyagrammar} labelled as a \texttt{stmt} node. For example common expressions such as assignments are usually statements, or
an if-else block or loop. Actually, in Python, class and function definitions are really a special form of assignment too and so are also statements.

The current implementation for our obfuscation and analysis tool reads in program source to an AST. This allows us to analyse the code easily
but also destroys information left in the layout of the code. This is not a problem when obfuscating as we want to remove as much information
as we can when it is not important to the running of the program.

For the analyser we have slightly more trouble in losing this information. For now we will take a similar route to the obfuscator and assume this
does not matter as the program will probably already be obfuscated already and lacking in any meanful layout. In actual fact, the AST when created
will still contain information about statements and line/column numbers. This could be used to recover the lost information, however as soon
as we perform any other transformation on the AST, there is no guarantee line numbers exist or make sense. This could become a later extension;
to gain grouping information from the AST.

Even though we are discussing it, grouping is not a great issue as layout obfuscation is not our primary concern. We want now to learn how
to reorder statements without breaking the program. This means we should be able to receive an ordered list of AST nodes and calculate somehow
the other permutations of statments which have the same visible output. Once we have a method for this we can obfuscate or deobfuscate by our choice
of permutation. An obfuscator would value orderings holding less information and a deobfuscator would favour those with more. How we decide which
orderings hold the information will a a bridge to cross later on.

Our approach to finding possible statement orderings will be for each node in the list to build a list of every other node in the list that that
particular node is dependant on. More simply, if the effect of statement A could change the effect of statement B, then B depends on A. For internal
data such as variable assignments this means if A changes a memory region R that B accesses at some point in the future, then B depends on A.

Also we must look at statements that may perform external changes such as a print statement. An observer of the program would notice immediately
a change in order of these. Therefore all statements capable of change the world external to the program must remain in order relative to each other.
We can make sure of this by assuming any function with external effect depends on the IO function immediately previous to it.

When working out possible permutations we can now just search for options that neither add nor remove dependencies between the instructions.

\subsection{Looking for dependencies}

In calculating dependencies, we will start with the simplest possible list of statements. From here we will expand our reasoning slowly until
we can analyse a substantial portion of the Python language.

\subsubsection{Simplest Case}

Our simplest case would be one where none of the instructions depend on each other. We will ignore external output throughout as we already know
all we need to do is keep any such functions in order. We allow only assignments here as possible statements, and those that bind constants to
variables. The assignments should have no effect other than to add the constant into a new region of memory and assign the given name to
reference this location. This should model a Python program if all identifiers on the left hand side of the assignment are simple names.
(We also ignore the changes Python will make to certain data such as that returned by the \texttt{locals()} built-in function).

An example:

\begin{lstlisting}
a = 1
b = 2
c = []
c = 3
\end{lstlisting}

Here the instructions could move to any order. None of the assignments rely on the previous assignments of any other value to any other name. It's
worth looking at the two assignments of the same variable, \texttt{c}. If we reversed the order of these two statements we would finish the
statement list with either the local dictionary \texttt{\{a: 1, b: 2, c: []\}} or \texttt{\{a: 1, b: 2, c: 3\}}.

In fact this difference does not matter. This change is internal to the program and so not visible to an observer. As we have not specified
any future dependency on \texttt{c}, we can assume that nothing that can affect the observable behaviour of the program will use the value
of \texttt{c} - meaning the program remains correct.

\subsubsection{Slightly Harder}

Now we allow assignments of values that can either be constant or other local names. We will restrict all of our names to local scope as
we have not yet introduced the concept of scope to our model.

An example:

\begin{lstlisting}
a = 1
b = a
c = a
c = b
\end{lstlisting}

Now we can easily go through line by line and look at which names appear on the right of the assignment to gather a list of dependencies.

TODO - CONTINUE FROM HERE!-------------------------------------------------------------

Problem! What if we added one line to make:

\begin{lstlisting}
a = 1
b = a
d = e
c = a
c = b
\end{lstlisting}

Now we have a line that will cause error. 

\section{Opaque Predicates}

The second obfuscation technique we will implement will insert branches into the code that depend on
some opaque predicate \cite{taxobftrans}. This is a predicate that we as the obfuscator know the value of,
but an analyser will find it difficult to evaluate. The branches we will insert will jump either to our valid
program code, or another obfuscated version of our code or even some cleverly disguised garbage. The purpose of doing so being
that the increased number of branches in the program will confuse both a human reader and a programatic analyser.

To reverse the transformation, dead code analysis will be used. This means the analyser will seek to remove
branches where we know a program will always take a certain path. The success of this analysis
depends on both the strength of the analysis and the strength of the opaque predicate.

\section{Relocate or Implement me - TODO}

Both of the described transformations and their analysis will require careful testing. So far,
this has been done using Python's doc test library to write unit tests inside the docstrings
in each piece of code. It is likely a higher level approach will be more suitable later in
the project, testing a program's validity before and after obfuscations as well as the validity
of the analysis.

\section{Evaluation}

\subsection{How to Evaluate}

Evaluation of the final product will be difficult, this is mainly due to the lack of similar tools.
Comparison to other Python obfuscators is not viable as only the pyobfuscate tool is available to
use. While this does perform obfuscation on Python source, it does not operate on the same version of
the source or perform the same type of obfuscation. In fact most available obfuscators will deal with
layout transformation rather than control flow.

There are a few obfuscators that will deal with control flow obfuscation in other languages, for example
the Kava tool for Java is discussed in detail elsewhere \cite{taxobftrans}. We could attempt to compare these
tools with our own, however they tend to be written for much less flexible or dynamic languages than
Python (and hence are easier analysable). Indeed, it is one of the intentions of this project to assess the
extra difficulty a dynamic language such as Python adds when writing these tools, but to compare the final
product to one of these existing tools from such a different base would be misleading.

As well as comparing to similar tools, we have the option to assess an obfuscator's merit based on
its ability to create output that withstands reverse engineering or analysis. In fact this should be
a much better analysis of the product as we can say if the software is good at what it is designed to do, rather
than whether it is just better at performing the same function as another tool.

To aid in this form of evaluation we will need tools to analyse the obfuscated source code. There are plenty
mentioned in the background section, however these tend to be designed to optimise code or detect possible bugs and so
are not ideal.

The solution proposed for this project is to write tools for analysis along side the tools for obfuscation.
By doing this we can really target the analysis at detecting and reversing the particular transformations
that our obfuscator implements. Hopefully this should not create a great deal of extra work as the analysis
needed for reversing a transformation is often likely to be the same form of analysis performed to make that
transformation in the first place, so the work is already done.

Of course this is not a perfect solution. Ideally analytic tools would be written by someone else without
knowledge of the specific obfuscator. This would move closer to representing a reverse-engineer or analytic
tool in the real world, as hopefully neither would be able to ascertain the software used to perform the obfuscation
or the specific techniques used on specific code locations. In theory this should give the analytic tool an
advantage, lowering our expected potency for the obfuscator.

Another problem caused by the same author writing both sides of a competing set of software is that the competition
may not be so fierce as in the real world. Any design oversights in one half of the software will likely show up
in the other, rather than being exploited as would hopefully be the case with two free thinking developers. As a real
example, the Java decompiler Mocha will crash if it finds extra statements after a function has returned
\cite{hosemocha}[p4]. The bytecode obfuscator HoseMocha uses this to prevent Mocha from decompiling programs. Had these two
pieces of software been written by the same developer, one whose decompiler doesn't check for the unlikely case described,
then it is probable that this case would never have been thought of for the obfuscator - and HoseMocha would never have
been created.

We do not have the option of contracting a separate developer to help with this evaluation. The best solution to mitigate the effect
of this is to compare the development of the analysis tool to the available analytic tools discussed in the background section. Although
these have different primary functions, at least some functionality will overlap and allow a loose comparison. From this it
should be possible to determine if our analysis tool is sub-par or better than average and to judge the obfuscator
accordingly.

\subsection{What to Evaluate}

We have looked at how we can evaluate the software, and we know the tools we will use to do so. What we don't know yet is
the specific criteria that we will be evaluating. 

As we already know, the aim of obfuscation is to confuse a human reader or a programmatic analysis. In measuring the effectiveness
of a particular obfuscation we are actually attempting to quantify the additional confusion caused by it. This is not an easy task
as confusion is very subjective to a particular viewer or program.

Previous attempts to do this tend to use program complexity metrics to measure the impact of a particular obfuscation. Many fail to
actually quantify transformation benefit, preferring instead to give a rough estimation, although recently there have been improvements in
this area \cite{obfquant}.

Although these metrics can be used during the obfuscating and analysis, they are unlikely to help with evaluation as we are
not proposing any new transformations. Instead we are comparing the same transformation in an environment with looser rules than usual.
In this case, complexity metrics will be very similar if not the same and so not helpful to us.

A much more helpful approach will be to discuss freely (and using the metrics) the challenges faced in implementing these obfuscations
in Python as well as breaking them. This can be compared to other languages and implementations. Finally the comparative performances
of the obfuscator and analyser will be assessed on some example programs.

\section{Conclusions and Future Work}

TODO - this section, aaah

\bibliographystyle{plain}
\bibliography{final}

\end{document}
